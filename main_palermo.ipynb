{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Try:\n",
    "\n",
    "* Remove noisy sites and meter readings (site id)\n",
    "* rolling statistic\n",
    "* Site specific indicators\n",
    "* Treat categorical missing / NaNs\n",
    "\n",
    "* X Add building and site id features (see https://www.kaggle.com/aitude/ashrae-kfold-lightgbm-without-leak-1-08)\n",
    "    * Set categorical dataset in lgbm fit\n",
    "* X Research validation strategy and implement\n",
    "* X 'Primary use' indicator\n",
    "* X Additional datebased features (month and quarterly indicators, time trends)\n",
    "* X LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palermopenano/miniconda3/envs/cpa/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN = pathlib.Path('/Users/palermopenano/personal/kaggle_energy')\n",
    "SUBMISSIONS_PATH = MAIN / 'submissions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = False\n",
    "train_full = False         # False to do KFold CV, True to train on full dataset\n",
    "create_submission = False  # True to generate submission csv on test\n",
    "submission_name = 'submission_2019-11-24_add_building_site_features.csv'\n",
    "# submission_name = 'sampleAAA.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC (does not change)\n",
    "train = pd.read_csv(MAIN / 'data' / 'train.csv')\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'], infer_datetime_format=True)\n",
    "\n",
    "building_metadata = pd.read_csv(MAIN / 'data' / 'building_metadata.csv')\n",
    "\n",
    "weather_train = pd.read_csv(MAIN / 'data' / 'weather_train.csv')\n",
    "weather_train['timestamp'] = pd.to_datetime(weather_train['timestamp'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute rolling stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!\n",
    "# Rolling statistic for weather data\n",
    "\n",
    "cols_rol = [\n",
    "    'air_temperature', \n",
    "    'dew_temperature',\n",
    "    'sea_level_pressure',\n",
    "    'wind_speed'\n",
    "]\n",
    "period = 24\n",
    "\n",
    "tmp = rolling_stat(\n",
    "    weather_train, 'timestamp', ['site_id'], \n",
    "    cols_rol, period, np.mean\n",
    ")\n",
    "weather_train = weather_train.drop(cols_rol, 1)\n",
    "weather_train = weather_train.merge(tmp, how='inner', on=['site_id', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20216100, 4)\n"
     ]
    }
   ],
   "source": [
    "# Take only a random sample of n buildings\n",
    "if sample:\n",
    "    train, randbuilding = df_sample_random_buildings(train, 'building_id', n=10)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min time 2016-01-01 00:00:00\n",
      "Max time 2016-12-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# DNC\n",
    "train = train.merge(building_metadata, on='building_id', how='left')\n",
    "train = train.merge(weather_train, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "print(\n",
    "    f\"Min time {train['timestamp'].min()}\",\n",
    "    f\"Max time {train['timestamp'].max()}\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2622.02 MB\n",
      "['building_id', 'meter', 'meter_reading', 'site_id', 'primary_use', 'square_feet', 'year_built', 'floor_count', 'cloud_coverage', 'precip_depth_1_hr', 'wind_direction', 'air_temperature', 'dew_temperature', 'sea_level_pressure', 'wind_speed']\n",
      "Memory usage after optimization is: 1253.17 MB\n",
      "Decreased by 52.2%\n"
     ]
    }
   ],
   "source": [
    "# Reduce memory usage\n",
    "train = reduce_mem_usage(train, cols_exclude=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: take log of square_feet\n",
    "train['square_feet'] = np.log1p(train['square_feet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: Add datebased features\n",
    "# Monday is 0\n",
    "# If dayofweek is 5 or 6, then it is a weekend\n",
    "# // is \"floored\" division (i.e. 6//5 is equal to 1, 3//5 is 0)\n",
    "\n",
    "add_datepart(\n",
    "    train, 'timestamp', datetimeformat=None,\n",
    "    drop=False, time=True, errors=\"raise\"\n",
    ")\n",
    "train[\"weekend\"] = train[\"timestamp\"].dt.weekday // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precip_depth_1_hr_nan</th>\n",
       "      <th>precip_depth_1_hr_isTrace</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216095</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216096</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216097</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216098</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216099</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20216100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          precip_depth_1_hr_nan  precip_depth_1_hr_isTrace  precip_depth_1_hr\n",
       "0                          True                      False                0.0\n",
       "1                          True                      False                0.0\n",
       "2                          True                      False                0.0\n",
       "3                          True                      False                0.0\n",
       "4                          True                      False                0.0\n",
       "...                         ...                        ...                ...\n",
       "20216095                  False                       True                0.0\n",
       "20216096                  False                       True                0.0\n",
       "20216097                  False                       True                0.0\n",
       "20216098                  False                       True                0.0\n",
       "20216099                  False                       True                0.0\n",
       "\n",
       "[20216100 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering: precip_depth_1\n",
    "# Convert -1 and NaN precipitation to 0\n",
    "# Create trace rain indicator\n",
    "# Create NaN indicator\n",
    "\n",
    "def precip_depth_1_hr_FE(df, m):\n",
    "    df['precip_depth_1_hr_nan'] = df['precip_depth_1_hr'].isna()\n",
    "    \n",
    "    if m:\n",
    "        df.loc[df['precip_depth_1_hr'].isna(), 'precip_depth_1_hr'] = m\n",
    "    else:\n",
    "        m = df['precip_depth_1_hr'].median()\n",
    "        df.loc[df['precip_depth_1_hr'].isna(), 'precip_depth_1_hr'] = m\n",
    "\n",
    "    df['precip_depth_1_hr_isTrace'] = (df['precip_depth_1_hr'] == -1)\n",
    "    df.loc[df['precip_depth_1_hr'] == -1, 'precip_depth_1_hr'] = 0\n",
    "    return df, m\n",
    "\n",
    "train, precip_m = precip_depth_1_hr_FE(train, m=None)\n",
    "train[['precip_depth_1_hr_nan', 'precip_depth_1_hr_isTrace', 'precip_depth_1_hr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_direction_nan</th>\n",
       "      <th>wind_direction_sin</th>\n",
       "      <th>wind_direction_cos</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216095</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216096</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216097</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216098</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216099</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20216100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          wind_direction_nan  wind_direction_sin  wind_direction_cos  \\\n",
       "0                      False        0.000000e+00                 1.0   \n",
       "1                      False        0.000000e+00                 1.0   \n",
       "2                      False        0.000000e+00                 1.0   \n",
       "3                      False        0.000000e+00                 1.0   \n",
       "4                      False        0.000000e+00                 1.0   \n",
       "...                      ...                 ...                 ...   \n",
       "20216095               False       -8.742278e-08                -1.0   \n",
       "20216096               False       -8.742278e-08                -1.0   \n",
       "20216097               False       -8.742278e-08                -1.0   \n",
       "20216098               False       -8.742278e-08                -1.0   \n",
       "20216099               False       -8.742278e-08                -1.0   \n",
       "\n",
       "          wind_direction  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "...                  ...  \n",
       "20216095           180.0  \n",
       "20216096           180.0  \n",
       "20216097           180.0  \n",
       "20216098           180.0  \n",
       "20216099           180.0  \n",
       "\n",
       "[20216100 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering: wind_direction\n",
    "# Replace nan with median wind_directin angle\n",
    "# Create nan indicator\n",
    "# Convert to sine and cosine features\n",
    "\n",
    "def wind_direction_FE(df, m=None):\n",
    "    df['wind_direction_nan'] = df['wind_direction'].isna()\n",
    "\n",
    "    if m:\n",
    "        df.loc[df['wind_direction'].isna(), 'wind_direction'] = m\n",
    "    else:\n",
    "        m = df['wind_direction'].median()\n",
    "        df.loc[df['wind_direction'].isna(), 'wind_direction'] = m\n",
    "\n",
    "    df['wind_direction_sin'] = np.sin(np.radians(df['wind_direction']))\n",
    "    df['wind_direction_cos'] = np.cos(np.radians(df['wind_direction']))\n",
    "    return df, m\n",
    "\n",
    "train, wind_direction_m = wind_direction_FE(train, m=None)\n",
    "train[['wind_direction_nan','wind_direction_sin','wind_direction_cos','wind_direction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: primary_use\n",
    "# Apply label encoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train['primary_use'] = le.fit_transform(train['primary_use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Log Meter Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (20216100,) 0.0 16.902212142944336\n"
     ]
    }
   ],
   "source": [
    "# DNC\n",
    "train['meter_reading'] = np.where(\n",
    "    train['meter_reading']>=0, train['meter_reading'], 0)\n",
    "y = np.log1p(train['meter_reading'])\n",
    "\n",
    "print(y.ndim, y.shape, y.min(), y.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Features to Include in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feats = [\n",
    "        'square_feet',\n",
    "        'floor_count',\n",
    "        'air_temperature',\n",
    "        'dew_temperature',\n",
    "        'sea_level_pressure',\n",
    "        'wind_speed',\n",
    "        'precip_depth_1_hr',\n",
    "        'precip_depth_1_hr_nan', \n",
    "        'precip_depth_1_hr_isTrace',\n",
    "]\n",
    "\n",
    "cat_feats = [\n",
    "    'timestampDayofweek',\n",
    "    'primary_use',\n",
    "    'year_built',\n",
    "    'timestampMonth',\n",
    "#     'timestampWeek',\n",
    "    'timestampHour',\n",
    "    'weekend',\n",
    "    'site_id',\n",
    "    'building_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train['timestamp'].is_monotonic_increasing:\n",
    "    raise Exception(\n",
    "        \"timestamp should be sorted in increasing order \"\n",
    "        \"for KFold validation to work properly\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 20216100 records\n",
      "Number of features: 17\n"
     ]
    }
   ],
   "source": [
    "# DNC\n",
    "train = train[cont_feats + cat_feats]\n",
    "print(\n",
    "    f\"Training on {train.shape[0]} records\",\n",
    "    f\"Number of features: {train.shape[1]}\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')  # CHANGED\n",
    "imputed_df = pd.DataFrame(imp.fit_transform(train))\n",
    "imputed_df.columns = train.columns\n",
    "train = imputed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold CV (Unshuffled)\n",
    "Variation of cv approach in \n",
    "\n",
    "https://www.kaggle.com/kimtaegwan/what-s-your-cv-method?scriptVersionId=22371767\n",
    "\n",
    "evaluated only on the second fold, since validation set for this are from a time period after the training set. Note disadvantage of current implementation of this approach: missing imputation by mean of a feature leaks into the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (10108050,) (10108050,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palermopenano/miniconda3/envs/cpa/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['building_id', 'primary_use', 'site_id', 'timestampDayofweek', 'timestampHour', 'timestampMonth', 'weekend', 'year_built']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's rmse: 1.72941\n"
     ]
    }
   ],
   "source": [
    "if not train_full:\n",
    "\n",
    "    folds = 2\n",
    "\n",
    "    kf = model_selection.KFold(\n",
    "        n_splits=folds, shuffle=False, random_state=42)\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(kf.split(train, y)):\n",
    "\n",
    "        # Skip first fold to avoid worst data leakage\n",
    "        # due to all training set time > validation set time\n",
    "        if fold_ == 0:\n",
    "            continue\n",
    "\n",
    "        print(fold_, trn_idx.shape, val_idx.shape)\n",
    "\n",
    "        # Note potential leakage here if missing imputation is done before \n",
    "        # before this cell\n",
    "        tr_x, tr_y = train.iloc[trn_idx], y[trn_idx]\n",
    "        vl_x, vl_y = train.iloc[val_idx], y[val_idx]\n",
    "\n",
    "#         tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "#         vl_data = lgb.Dataset(vl_x, label=vl_y) \n",
    "        \n",
    "        reg = lgb.LGBMRegressor(\n",
    "            learning_rate=0.05,\n",
    "            boosting=\"gbdt\",\n",
    "            n_estimators=3000,\n",
    "            feature_fraction=.7,\n",
    "            min_child_weight=3,\n",
    "            subsample=0.6,\n",
    "            colsample_bytree=.9,\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            n_jobs=8,\n",
    "            seed=27,\n",
    "            num_leaves=40\n",
    "        )\n",
    "\n",
    "        reg.fit(\n",
    "            tr_x, tr_y,\n",
    "            eval_set=[(vl_x, vl_y)],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=100,\n",
    "            categorical_feature=cat_feats\n",
    "        )\n",
    "\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full sample for submission\n",
    "if train_full:\n",
    "\n",
    "    print(\"Training on entire training dataset\")\n",
    "    # Number of estimators based on KFold CV results\n",
    "    n_estimators_cv = 500\n",
    "\n",
    "    reg = lgb.LGBMRegressor(\n",
    "        learning_rate=0.05,\n",
    "        boosting=\"gbdt\",\n",
    "        n_estimators=n_estimators_cv,\n",
    "        feature_fraction=.7,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=.9,\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        n_jobs=8,\n",
    "        seed=27,\n",
    "        num_leaves=40\n",
    "    )\n",
    "    reg.fit(\n",
    "        train, y,\n",
    "        categorical_feature=cat_feats\n",
    "    )\n",
    "    \n",
    "    # clf = LinearRegression()\n",
    "    # clf.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove reference and force garbage collection\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset to Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_submission:\n",
    "    # Evaluate on test set\n",
    "    test = pd.read_csv(MAIN / 'data' / 'test.csv')\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "\n",
    "    weather_test = pd.read_csv(MAIN / 'data' / 'weather_test.csv')\n",
    "    weather_test['timestamp'] = pd.to_datetime(weather_test['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Evaluation Set Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_submission:\n",
    "    tmp = rolling_stat(\n",
    "        weather_test, 'timestamp', ['site_id'], \n",
    "        cols_rol, period, np.mean\n",
    "    )\n",
    "    weather_test = weather_test.drop(cols_rol, 1)\n",
    "    weather_test = weather_test.merge(tmp, how='inner', on=['site_id', 'timestamp'])\n",
    "\n",
    "    # DNC\n",
    "    # Merge into training\n",
    "    test = test.merge(building_metadata, on='building_id', how='left')\n",
    "    test = test.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "    if sample:\n",
    "        test = test[test['building_id'].isin(randbuilding)]\n",
    "\n",
    "    print(\"Apply date operation...\")\n",
    "    add_datepart(\n",
    "        test, 'timestamp', datetimeformat=None,\n",
    "        drop=False, time=True, errors=\"raise\"\n",
    "    )\n",
    "    test[\"weekend\"] = test[\"timestamp\"].dt.weekday // 5\n",
    "\n",
    "    # Apply feature engineering to test set\n",
    "    print(\"Apply feature engineering and imputed values...\")\n",
    "    test,_ = precip_depth_1_hr_FE(test, m=precip_m)\n",
    "    test, _ = wind_direction_FE(test, m=wind_direction_m)\n",
    "    test['primary_use'] = le.transform(test['primary_use'])  # CHANGED\n",
    "\n",
    "    # Remove binding from namespace\n",
    "    # and force release of memory\n",
    "    del building_metadata, weather_train\n",
    "    gc.collect()\n",
    "\n",
    "    test = test[cont_feats + cat_feats + ['row_id']]\n",
    "    test['square_feet'] = np.log1p(test['square_feet'])\n",
    "\n",
    "    test_v = test.drop('row_id', 1).values\n",
    "    test_v = imp.transform(test_v)\n",
    "    test_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_submission:\n",
    "    print(\"Generating submission\")\n",
    "\n",
    "    test['meter_reading'] = np.expm1(reg.predict(test_v))\n",
    "    # Save predictions as a column in a df\n",
    "    # Clip to a min of 0 and infinity (a_max is None)\n",
    "    test['meter_reading'] = np.clip(test['meter_reading'].values, 0, None)\n",
    "    sample_submission = test[['row_id', 'meter_reading']]\n",
    "\n",
    "    sample_submission.loc[:,'meter_reading'] = (\n",
    "        sample_submission.loc[:, 'meter_reading'].\n",
    "        astype('float32').\n",
    "        round(2)\n",
    "    )\n",
    "\n",
    "    sample_submission.loc[:,'row_id'] = (\n",
    "        sample_submission.loc[:, 'row_id'].\n",
    "        astype('int32')\n",
    "    )\n",
    "\n",
    "    sample_submission.memory_usage().sum() // 1024**2\n",
    "\n",
    "    # DNC\n",
    "    sample_submission.to_csv(SUBMISSIONS_PATH / submission_name, index=False)\n",
    "\n",
    "    print(sample_submission.shape)\n",
    "    print(sample_submission['meter_reading'].min(), sample_submission['meter_reading'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
