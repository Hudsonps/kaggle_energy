{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Try:\n",
    "\n",
    "* Research validation strategy and implement\n",
    "* Remove noisy sites and meter readings (site id)\n",
    "* rolling statistic\n",
    "* Site specific indicators\n",
    "* Treat categorical missing / NaNs\n",
    "* X 'Primary use' indicator\n",
    "* X Additional datebased features (month and quarterly indicators, time trends)\n",
    "* X LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN = pathlib.Path('/Users/palermopenano/personal/kaggle_energy')\n",
    "SUBMISSIONS_PATH = MAIN / 'submissions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = True\n",
    "\n",
    "eval_test = True\n",
    "create_submission = True\n",
    "submission_name = 'submission_2019-11-22_rolling_avg_weather_v2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC (does not change)\n",
    "train = pd.read_csv(MAIN / 'data' / 'train.csv')\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'], infer_datetime_format=True)\n",
    "\n",
    "building_metadata = pd.read_csv(MAIN / 'data' / 'building_metadata.csv')\n",
    "\n",
    "weather_train = pd.read_csv(MAIN / 'data' / 'weather_train.csv')\n",
    "weather_train['timestamp'] = pd.to_datetime(weather_train['timestamp'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute rolling stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!\n",
    "# Rolling statistic for weather data\n",
    "\n",
    "cols_rol = [\n",
    "    'air_temperature', \n",
    "    'dew_temperature',\n",
    "    'sea_level_pressure',\n",
    "    'wind_speed'\n",
    "]\n",
    "period = 24\n",
    "\n",
    "tmp = rolling_stat(\n",
    "    weather_train, 'timestamp', ['site_id'], \n",
    "    cols_rol, period, np.mean\n",
    ")\n",
    "weather_train = weather_train.drop(cols_rol, 1)\n",
    "weather_train = weather_train.merge(tmp, how='inner', on=['site_id', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132424, 4)\n"
     ]
    }
   ],
   "source": [
    "# Take only a random sample of n buildings\n",
    "if sample:\n",
    "    train, randbuilding = df_sample_random_buildings(train, 'building_id', n=10)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC\n",
    "train = train.merge(building_metadata, on='building_id', how='left')\n",
    "train = train.merge(weather_train, on=['site_id', 'timestamp'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 17.18 MB\n",
      "['building_id', 'meter', 'meter_reading', 'site_id', 'primary_use', 'square_feet', 'year_built', 'floor_count', 'cloud_coverage', 'precip_depth_1_hr', 'wind_direction', 'air_temperature', 'dew_temperature', 'sea_level_pressure', 'wind_speed']\n",
      "Memory usage after optimization is: 8.21 MB\n",
      "Decreased by 52.2%\n"
     ]
    }
   ],
   "source": [
    "# Reduce memory usage\n",
    "train = reduce_mem_usage(train, cols_exclude=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: take log of square_feet\n",
    "train['square_feet'] = np.log1p(train['square_feet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: Add datebased features\n",
    "# Monday is 0\n",
    "# If dayofweek is 5 or 6, then it is a weekend\n",
    "# // is quotient division (i.e. 6//5 is equal to 1, 3//5 is 0)\n",
    "\n",
    "add_datepart(\n",
    "    train, 'timestamp', datetimeformat=None,\n",
    "    drop=False, time=True, errors=\"raise\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precip_depth_1_hr_nan</th>\n",
       "      <th>precip_depth_1_hr_isTrace</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132419</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132420</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132421</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132422</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132423</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132424 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        precip_depth_1_hr_nan  precip_depth_1_hr_isTrace  precip_depth_1_hr\n",
       "0                        True                      False                0.0\n",
       "1                        True                      False                0.0\n",
       "2                        True                      False                0.0\n",
       "3                        True                      False                0.0\n",
       "4                        True                      False                0.0\n",
       "...                       ...                        ...                ...\n",
       "132419                  False                       True                0.0\n",
       "132420                  False                       True                0.0\n",
       "132421                  False                       True                0.0\n",
       "132422                  False                       True                0.0\n",
       "132423                  False                       True                0.0\n",
       "\n",
       "[132424 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering: precip_depth_1\n",
    "# Convert -1 and NaN precipitation to 0\n",
    "# Create trace rain indicator\n",
    "# Create NaN indicator\n",
    "\n",
    "def precip_depth_1_hr_FE(df, m):\n",
    "    df['precip_depth_1_hr_nan'] = df['precip_depth_1_hr'].isna()\n",
    "    \n",
    "    if m:\n",
    "        df.loc[df['precip_depth_1_hr'].isna(), 'precip_depth_1_hr'] = m\n",
    "    else:\n",
    "        m = df['precip_depth_1_hr'].median()\n",
    "        df.loc[df['precip_depth_1_hr'].isna(), 'precip_depth_1_hr'] = m\n",
    "\n",
    "    df['precip_depth_1_hr_isTrace'] = (df['precip_depth_1_hr'] == -1)\n",
    "    df.loc[df['precip_depth_1_hr'] == -1, 'precip_depth_1_hr'] = 0\n",
    "    return df, m\n",
    "\n",
    "train, precip_m = precip_depth_1_hr_FE(train, m=None)\n",
    "train[['precip_depth_1_hr_nan', 'precip_depth_1_hr_isTrace', 'precip_depth_1_hr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_direction_nan</th>\n",
       "      <th>wind_direction_sin</th>\n",
       "      <th>wind_direction_cos</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.736484e-01</td>\n",
       "      <td>0.984808</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.736482e-01</td>\n",
       "      <td>-0.984808</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.736482e-01</td>\n",
       "      <td>-0.984808</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132419</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132420</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132421</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132422</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132423</td>\n",
       "      <td>False</td>\n",
       "      <td>-8.742278e-08</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132424 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wind_direction_nan  wind_direction_sin  wind_direction_cos  \\\n",
       "0                    False        0.000000e+00            1.000000   \n",
       "1                    False       -8.660254e-01           -0.500000   \n",
       "2                    False       -1.736484e-01            0.984808   \n",
       "3                     True       -1.736482e-01           -0.984808   \n",
       "4                     True       -1.736482e-01           -0.984808   \n",
       "...                    ...                 ...                 ...   \n",
       "132419               False       -8.742278e-08           -1.000000   \n",
       "132420               False       -8.742278e-08           -1.000000   \n",
       "132421               False       -8.742278e-08           -1.000000   \n",
       "132422               False       -8.742278e-08           -1.000000   \n",
       "132423               False       -8.742278e-08           -1.000000   \n",
       "\n",
       "        wind_direction  \n",
       "0                  0.0  \n",
       "1                240.0  \n",
       "2                350.0  \n",
       "3                190.0  \n",
       "4                190.0  \n",
       "...                ...  \n",
       "132419           180.0  \n",
       "132420           180.0  \n",
       "132421           180.0  \n",
       "132422           180.0  \n",
       "132423           180.0  \n",
       "\n",
       "[132424 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering: wind_direction\n",
    "# Replace nan with median wind_directin angle\n",
    "# Create nan indicator\n",
    "# Convert to sine and cosine features\n",
    "\n",
    "def wind_direction_FE(df, m=None):\n",
    "    df['wind_direction_nan'] = df['wind_direction'].isna()\n",
    "\n",
    "    if m:\n",
    "        df.loc[df['wind_direction'].isna(), 'wind_direction'] = m\n",
    "    else:\n",
    "        m = train['wind_direction'].median()\n",
    "        df.loc[train['wind_direction'].isna(), 'wind_direction'] = m\n",
    "\n",
    "    df['wind_direction_sin'] = np.sin(np.radians(df['wind_direction']))\n",
    "    df['wind_direction_cos'] = np.cos(np.radians(df['wind_direction']))\n",
    "    return df, m\n",
    "\n",
    "train, wind_direction_m = wind_direction_FE(train, m=None)\n",
    "train[['wind_direction_nan','wind_direction_sin','wind_direction_cos','wind_direction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: primary_use\n",
    "# Apply label encoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train['primary_use'] = le.fit_transform(train['primary_use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Log Meter Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (132424,) 0.0 9.107102\n"
     ]
    }
   ],
   "source": [
    "# DNC\n",
    "train['meter_reading'] = np.where(\n",
    "    train['meter_reading']>=0, train['meter_reading'], 0)\n",
    "y = np.log1p(train['meter_reading'].values)\n",
    "\n",
    "print(y.ndim, y.shape, y.min(), y.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Features to Include in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "        'square_feet',\n",
    "        'year_built',\n",
    "        'floor_count',\n",
    "        'primary_use',  # CHANGED\n",
    "        'air_temperature',\n",
    "        'dew_temperature',\n",
    "        'sea_level_pressure',\n",
    "#         'wind_direction_nan',\n",
    "#         'wind_direction_sin',\n",
    "#         'wind_direction_cos',\n",
    "        'wind_speed',\n",
    "        'precip_depth_1_hr',\n",
    "        'precip_depth_1_hr_nan', \n",
    "        'precip_depth_1_hr_isTrace',\n",
    "        'timestampMonth',\n",
    "#         'timestampWeek',\n",
    "#         'timestampDay',\n",
    "        'timestampDayofweek',\n",
    "#         'timestampDayofyear',\n",
    "#         'timestampIs_month_end',\n",
    "#         'timestampIs_month_start',\n",
    "#         'timestampIs_quarter_end',\n",
    "#         'timestampIs_quarter_start',\n",
    "#         'timestampIs_year_end',\n",
    "#         'timestampIs_year_start',\n",
    "        'timestampHour',\n",
    "#         'timestampElapsed'\n",
    "]\n",
    "\n",
    "# Hudson's features 2019-11-20\n",
    "# features = [\n",
    "#         'square_feet',\n",
    "#         'year_built',\n",
    "#         'air_temperature',\n",
    "#         'dew_temperature',\n",
    "#         'wind_speed',\n",
    "#         'floor_count',\n",
    "#         'timestampMonth',\n",
    "#         'timestampWeek',\n",
    "#         'timestampHour',\n",
    "# ]\n",
    "\n",
    "# features = [\n",
    "#         'square_feet',\n",
    "#         'year_built',\n",
    "#         'floor_count',\n",
    "#         'weekend'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC\n",
    "train = train[features]\n",
    "train = train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')  # CHANGED\n",
    "imp.fit(train)\n",
    "train = imp.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor(boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "              colsample_bytree=0.9, importance_type='split', learning_rate=0.1,\n",
      "              max_depth=4, metric='rmse', min_child_samples=20,\n",
      "              min_child_weight=3, min_split_gain=0.0, n_estimators=500,\n",
      "              n_jobs=8, num_leaves=20, objective='regression',\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
      "              scale_pos_weight=1, seed=27, silent=True, subsample=0.6,\n",
      "              subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "print(Models.lgbm)\n",
    "\n",
    "# # LightGBM\n",
    "# clf = Models.lgbm\n",
    "# clf.fit(train, y)\n",
    "\n",
    "# clf = LinearRegression()\n",
    "# clf.fit(train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (105939,) (26485,)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\tvalid_0's rmse: 1.26977\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[308]\tvalid_0's rmse: 1.26688\n",
      "------------------\n",
      "\n",
      "1 (105939,) (26485,)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's rmse: 1.32907\n",
      "------------------\n",
      "\n",
      "2 (105939,) (26485,)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's rmse: 1.14973\n",
      "------------------\n",
      "\n",
      "3 (105939,) (26485,)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's rmse: 1.30129\n",
      "------------------\n",
      "\n",
      "4 (105940,) (26484,)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's rmse: 1.41614\n",
      "------------------\n",
      "\n",
      "oof_RMSE :  1.2955392298841502\n"
     ]
    }
   ],
   "source": [
    "# !!! Ensure sorted by time\n",
    "# Source: https://www.kaggle.com/kimtaegwan/what-s-your-cv-method?scriptVersionId=22371767\n",
    "\n",
    "folds = 5\n",
    "seed = 42\n",
    "\n",
    "kf = model_selection.KFold(\n",
    "    n_splits=folds, shuffle=False, random_state=seed)\n",
    "models = []\n",
    "oof = np.zeros(len(train))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(kf.split(train, y)):\n",
    "    \n",
    "    # Skip first fold to avoid worst data leakage\n",
    "    # due to all training set time > validation set time\n",
    "#     if fold_ == 0:\n",
    "#         continue\n",
    "    \n",
    "    print(fold_, trn_idx.shape, val_idx.shape)\n",
    "\n",
    "    # Note potential leakage here if missing imputation is done before \n",
    "    # before this cell\n",
    "    tr_x, tr_y = train[trn_idx], y[trn_idx]\n",
    "    vl_x, vl_y = train[val_idx], y[val_idx]\n",
    "    \n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "\n",
    "    reg = lgb.LGBMRegressor(\n",
    "        learning_rate=0.1,   # CHANGE\n",
    "        boosting=\"gbdt\",\n",
    "        n_estimators=500,\n",
    "        max_depth=4,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=.9,\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        n_jobs=8,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27,\n",
    "        num_leaves=20\n",
    "    )\n",
    "#     reg = lgb.LGBMRegressor(n_estimators=6000,\n",
    "#                                 learning_rate=0.05,\n",
    "#                                 feature_fraction=0.7,\n",
    "#                                 subsample=0.4,\n",
    "#                                 num_leaves=40,\n",
    "#                                 metric='rmse')\n",
    "    reg.fit(\n",
    "        tr_x, tr_y,\n",
    "        eval_set=[(vl_x, vl_y)],\n",
    "        early_stopping_rounds=200,\n",
    "        verbose=500\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set and save in oof array\n",
    "    oof[val_idx] = reg.predict(vl_x)\n",
    "\n",
    "    models.append(reg)\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"------------------\\n\")\n",
    "print(\n",
    "    'oof_RMSE : ' ,\n",
    "    np.sqrt(metrics.mean_squared_error(oof, y))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove reference and force garbage collection\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset to Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_test:\n",
    "    # Evaluate on test set\n",
    "    test = pd.read_csv(MAIN / 'data' / 'test.csv')\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "\n",
    "    weather_test = pd.read_csv(MAIN / 'data' / 'weather_test.csv')\n",
    "    weather_test['timestamp'] = pd.to_datetime(weather_test['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "# !!! Define test and weather test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Evaluation Set Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply date operation...\n",
      "Apply feature engineering and imputed values...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(41697600, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = rolling_stat(\n",
    "    weather_test, 'timestamp', ['site_id'], \n",
    "    cols_rol, period, np.mean\n",
    ")\n",
    "weather_test = weather_test.drop(cols_rol, 1)\n",
    "weather_test = weather_test.merge(tmp, how='inner', on=['site_id', 'timestamp'])\n",
    "\n",
    "# DNC\n",
    "# Merge into training\n",
    "test = test.merge(building_metadata, on='building_id', how='left')\n",
    "test = test.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "if sample:\n",
    "    test = test[test['building_id'].isin(randbuilding)]\n",
    "\n",
    "print(\"Apply date operation...\")\n",
    "add_datepart(\n",
    "    test, 'timestamp', datetimeformat=None,\n",
    "    drop=False, time=True, errors=\"raise\"\n",
    ")\n",
    "\n",
    "# Apply feature engineering to test set\n",
    "print(\"Apply feature engineering and imputed values...\")\n",
    "test,_ = precip_depth_1_hr_FE(test, m=precip_m)\n",
    "test, _ = wind_direction_FE(test, m=wind_direction_m)\n",
    "test['primary_use'] = le.transform(test['primary_use'])  # CHANGED\n",
    "\n",
    "# Remove binding from namespace\n",
    "# and force release of memory\n",
    "del building_metadata, weather_train\n",
    "gc.collect()\n",
    "\n",
    "test = test[features + ['row_id']]\n",
    "test['square_feet'] = np.log1p(test['square_feet'].values)\n",
    "\n",
    "test_v = test.drop('row_id', 1).values\n",
    "test_v = imp.transform(test_v)\n",
    "test_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palermopenano/miniconda3/envs/cpa/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41697600, 2)\n",
      "0.0 8493.9501953125\n"
     ]
    }
   ],
   "source": [
    "if create_submission and not sample:\n",
    "    print(\"Generating submission\")\n",
    "\n",
    "    # DNC\n",
    "    sample_submission = pd.read_csv(MAIN / 'data' / 'sample_submission.csv')\n",
    "\n",
    "    test['meter_reading'] = np.expm1(clf.predict(test_v))\n",
    "    # Save predictions as a column in a df\n",
    "    # Clip to a min of 0 and infinity (a_max is None)\n",
    "    test['meter_reading'] = np.clip(test['meter_reading'].values, 0, None)\n",
    "    sample_submission = test[['row_id', 'meter_reading']]\n",
    "\n",
    "    sample_submission.loc[:,'meter_reading'] = (\n",
    "        sample_submission.loc[:, 'meter_reading'].\n",
    "        astype('float32').\n",
    "        round(2)\n",
    "    )\n",
    "\n",
    "    sample_submission.loc[:,'row_id'] = (\n",
    "        sample_submission.loc[:, 'row_id'].\n",
    "        astype('int32')\n",
    "    )\n",
    "\n",
    "    sample_submission.memory_usage().sum() // 1024**2\n",
    "\n",
    "    # DNC\n",
    "    sample_submission.to_csv(SUBMISSIONS_PATH / submission_name, index=False)\n",
    "    \n",
    "    print(sample_submission.shape)\n",
    "    print(sample_submission['meter_reading'].min(), sample_submission['meter_reading'].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
