{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Try:\n",
    "\n",
    "* lag values!\n",
    "* rolling statistic\n",
    "* 'Primary use' indicator\n",
    "* Site specific indicators\n",
    "* Treat missing / NaNs\n",
    "* X Additional datebased features (month and quarterly indicators, time trends)\n",
    "* X LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palermopenano/miniconda3/envs/cpa/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import gc\n",
    "import datetime\n",
    "from typing import Tuple, Type\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN = pathlib.Path('/Users/palermopenano/personal/kaggle_energy')\n",
    "SUBMISSIONS_PATH = MAIN / 'submissions'\n",
    "\n",
    "sample = False\n",
    "submission_name = 'lgbm_add_datebased_features_2019-11-19.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reduce memory usage function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Models:\n",
    "    lgbm = lgb.LGBMRegressor(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=500,\n",
    "        max_depth=4,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=.9,\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        n_jobs=8,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27,\n",
    "        num_leaves=20\n",
    "    )\n",
    "\n",
    "    \n",
    "def train_and_predict(\n",
    "    model: Type[Models],\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series\n",
    "    ) -> Tuple:\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "def df_sample_random_buildings(df, b_col, n=500):\n",
    "    '''Generate a sample of the dataset based\n",
    "    on randomly selected ruts\n",
    "    '''\n",
    "    np.random.seed(42)\n",
    "    randbuilding = np.random.choice(\n",
    "        df[b_col].unique(),\n",
    "        size=n,\n",
    "        replace=False\n",
    "    )\n",
    "    return df[df[b_col].isin(randbuilding)], randbuilding\n",
    "\n",
    "def print_full(df, num_rows=100):\n",
    "    '''Print the first num_rows rows of dataframe in full\n",
    "\n",
    "    Resets display options back to default after printing\n",
    "    '''\n",
    "    pd.set_option('display.max_rows', len(df))\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 2000)\n",
    "    pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    display(df.iloc[0:num_rows])\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "    pd.reset_option('display.max_colwidth')\n",
    "    \n",
    "def add_datepart(\n",
    "    df, fldnames, datetimeformat,\n",
    "    drop=True, time=False, errors=\"raise\"\n",
    "):\n",
    "    if isinstance(fldnames, str):\n",
    "        fldnames = [fldnames]\n",
    "    for fldname in fldnames:\n",
    "        fld = df[fldname]\n",
    "        fld_dtype = fld.dtype\n",
    "        if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "            fld_dtype = np.datetime64\n",
    "\n",
    "        if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "            df[fldname + '_orig'] = df[fldname].copy()\n",
    "            df[fldname] = fld = pd.to_datetime(\n",
    "                fld, format=datetimeformat, errors=errors)\n",
    "        targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "        attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "                'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n",
    "                'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "        if time:\n",
    "            attr = attr + ['Hour', 'Minute', 'Second']\n",
    "        for n in attr:\n",
    "            df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "        df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n",
    "        if drop:\n",
    "            df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 616.95 MB\n",
      "Memory usage after optimization is: 173.90 MB\n",
      "Decreased by 71.8%\n"
     ]
    }
   ],
   "source": [
    "# DNC (does not change)\n",
    "train = pd.read_csv(MAIN / 'data' / 'train.csv')\n",
    "building_metadata = pd.read_csv(MAIN / 'data' / 'building_metadata.csv')\n",
    "weather_train = pd.read_csv(MAIN / 'data' / 'weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20216100, 4)\n"
     ]
    }
   ],
   "source": [
    "# Take only a random sample of n buildings\n",
    "if sample:\n",
    "    train, randbuilding = df_sample_random_buildings(train, 'building_id', n=10)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC\n",
    "train = train.merge(building_metadata, on='building_id', how='left')\n",
    "train = train.merge(weather_train, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "# Reduce memory usage\n",
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['square_feet'] = np.log1p(train['square_feet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monday is 0\n",
    "# If dayofweek is 5 or 6, then it is a weekend\n",
    "# // is quotient division (i.e. 6//5 is equal to 1, 3//5 is 0)\n",
    "\n",
    "add_datepart(\n",
    "    train, 'timestamp', datetimeformat=None,\n",
    "    drop=False, time=True, errors=\"raise\"\n",
    ")\n",
    "\n",
    "# train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "# train['weekend'] = (train['timestamp'].dt.dayofweek // 5 == 1).astype(float)\n",
    "# train['weekend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [c for c in train.columns if 'timestamp' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precip_depth_1_hr_nan</th>\n",
       "      <th>precip_depth_1_hr_isTrace</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216095</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216096</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216097</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216098</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216099</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20216100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          precip_depth_1_hr_nan  precip_depth_1_hr_isTrace  precip_depth_1_hr\n",
       "0                          True                      False                0.0\n",
       "1                          True                      False                0.0\n",
       "2                          True                      False                0.0\n",
       "3                          True                      False                0.0\n",
       "4                          True                      False                0.0\n",
       "...                         ...                        ...                ...\n",
       "20216095                  False                       True                0.0\n",
       "20216096                  False                       True                0.0\n",
       "20216097                  False                       True                0.0\n",
       "20216098                  False                       True                0.0\n",
       "20216099                  False                       True                0.0\n",
       "\n",
       "[20216100 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering: precip_depth_1\n",
    "# Convert -1 and NaN precipitation to 0\n",
    "# Create trace rain indicator\n",
    "# Create NaN indicator\n",
    "\n",
    "def precip_depth_1_hr_FE(df, m):\n",
    "    df['precip_depth_1_hr_nan'] = df['precip_depth_1_hr'].isna()\n",
    "    \n",
    "    if m:\n",
    "        df.loc[df['precip_depth_1_hr'].isna(), 'precip_depth_1_hr'] = m\n",
    "    else:\n",
    "        m = df['precip_depth_1_hr'].median()\n",
    "        df.loc[df['precip_depth_1_hr'].isna(), 'precip_depth_1_hr'] = m\n",
    "\n",
    "    df['precip_depth_1_hr_isTrace'] = (df['precip_depth_1_hr'] == -1)\n",
    "    df.loc[df['precip_depth_1_hr'] == -1, 'precip_depth_1_hr'] = 0\n",
    "    return df, m\n",
    "\n",
    "train, precip_m = precip_depth_1_hr_FE(train, m=None)\n",
    "train[['precip_depth_1_hr_nan', 'precip_depth_1_hr_isTrace', 'precip_depth_1_hr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_direction_nan</th>\n",
       "      <th>wind_direction_sin</th>\n",
       "      <th>wind_direction_cos</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216095</td>\n",
       "      <td>False</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216096</td>\n",
       "      <td>False</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216097</td>\n",
       "      <td>False</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216098</td>\n",
       "      <td>False</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20216099</td>\n",
       "      <td>False</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20216100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          wind_direction_nan  wind_direction_sin  wind_direction_cos  \\\n",
       "0                      False        0.000000e+00                 1.0   \n",
       "1                      False        0.000000e+00                 1.0   \n",
       "2                      False        0.000000e+00                 1.0   \n",
       "3                      False        0.000000e+00                 1.0   \n",
       "4                      False        0.000000e+00                 1.0   \n",
       "...                      ...                 ...                 ...   \n",
       "20216095               False        1.224647e-16                -1.0   \n",
       "20216096               False        1.224647e-16                -1.0   \n",
       "20216097               False        1.224647e-16                -1.0   \n",
       "20216098               False        1.224647e-16                -1.0   \n",
       "20216099               False        1.224647e-16                -1.0   \n",
       "\n",
       "          wind_direction  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "...                  ...  \n",
       "20216095           180.0  \n",
       "20216096           180.0  \n",
       "20216097           180.0  \n",
       "20216098           180.0  \n",
       "20216099           180.0  \n",
       "\n",
       "[20216100 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering: wind_direction\n",
    "# Replace nan with median wind_directin angle\n",
    "# Create nan indicator\n",
    "# Convert to sine and cosine features\n",
    "\n",
    "def wind_direction_FE(df, m=None):\n",
    "    df['wind_direction_nan'] = df['wind_direction'].isna()\n",
    "\n",
    "    if m:\n",
    "        df.loc[df['wind_direction'].isna(), 'wind_direction'] = m\n",
    "    else:\n",
    "        m = train['wind_direction'].median()\n",
    "        df.loc[train['wind_direction'].isna(), 'wind_direction'] = m\n",
    "\n",
    "    df['wind_direction_sin'] = np.sin(np.radians(df['wind_direction']))\n",
    "    df['wind_direction_cos'] = np.cos(np.radians(df['wind_direction']))\n",
    "    return df, m\n",
    "\n",
    "train, wind_direction_m = wind_direction_FE(train, m=None)\n",
    "train[['wind_direction_nan','wind_direction_sin','wind_direction_cos','wind_direction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC\n",
    "y = np.log1p(train['meter_reading'].values.reshape(-1,1))  # note reshape -1 to get original length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "        'square_feet',\n",
    "        'year_built',\n",
    "        'air_temperature',\n",
    "        'dew_temperature',\n",
    "        'sea_level_pressure',\n",
    "        'wind_direction_nan',\n",
    "        'wind_direction_sin',\n",
    "        'wind_direction_cos',\n",
    "        'wind_speed',\n",
    "        'precip_depth_1_hr',\n",
    "        'precip_depth_1_hr_nan', \n",
    "        'precip_depth_1_hr_isTrace',\n",
    "        'floor_count',\n",
    "        'timestampMonth',\n",
    "        'timestampWeek',\n",
    "        'timestampDay',\n",
    "        'timestampDayofweek',\n",
    "        'timestampDayofyear',\n",
    "        'timestampIs_month_end',\n",
    "        'timestampIs_month_start',\n",
    "        'timestampIs_quarter_end',\n",
    "        'timestampIs_quarter_start',\n",
    "        'timestampIs_year_end',\n",
    "        'timestampIs_year_start',\n",
    "        'timestampHour',\n",
    "        'timestampElapsed'\n",
    "]\n",
    "\n",
    "# features = [\n",
    "#         'square_feet',\n",
    "#         'year_built',\n",
    "#         'floor_count',\n",
    "#         'weekend'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC\n",
    "train = train[features]\n",
    "train = train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(train)\n",
    "train = imp.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.9,\n",
      "              importance_type='split', learning_rate=0.1, max_depth=4,\n",
      "              metric='rmse', min_child_samples=20, min_child_weight=3,\n",
      "              min_split_gain=0.0, n_estimators=500, n_jobs=8, num_leaves=20,\n",
      "              objective='regression', random_state=None, reg_alpha=0.0,\n",
      "              reg_lambda=0.0, scale_pos_weight=1, seed=27, silent=True,\n",
      "              subsample=0.6, subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palermopenano/miniconda3/envs/cpa/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print(Models.lgbm)\n",
    "# X_train = cat_to_numeric(X_train)\n",
    "# X_val = cat_to_numeric(X_val)\n",
    "\n",
    "# LightGBM\n",
    "clf = train_and_predict(\n",
    "    Models.lgbm,\n",
    "    train,\n",
    "    y,\n",
    ")\n",
    "\n",
    "# clf = LinearRegression()\n",
    "# clf.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove reference and force garbage collection\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Holdout for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC\n",
    "test = pd.read_csv(MAIN / 'data' / 'test.csv')\n",
    "weather_test = pd.read_csv(MAIN / 'data' / 'weather_test.csv')\n",
    "sample_submission = pd.read_csv(MAIN / 'data' / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply date operation...\n",
      "Apply feature engineering and imputed values...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(41697600, 26)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNC\n",
    "test = test.merge(building_metadata, on='building_id', how='left')\n",
    "test = test.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "if sample:\n",
    "    test = test[test['building_id'].isin(randbuilding)]\n",
    "\n",
    "print(\"Apply date operation...\")\n",
    "# test['weekend'] = (\n",
    "#     (pd.to_datetime(test['timestamp']).dt.dayofweek) // 5 == 1\n",
    "# ).astype(float)\n",
    "\n",
    "add_datepart(\n",
    "    test, 'timestamp', datetimeformat=None,\n",
    "    drop=False, time=True, errors=\"raise\"\n",
    ")\n",
    "\n",
    "# Apply feature engineering to test set\n",
    "print(\"Apply feature engineering and imputed values...\")\n",
    "test,_ = precip_depth_1_hr_FE(test, m=precip_m)\n",
    "test, _ = wind_direction_FE(test, m=wind_direction_m)\n",
    "\n",
    "# Remove binding from namespace\n",
    "# and force release of memory\n",
    "del building_metadata, weather_train\n",
    "gc.collect()\n",
    "\n",
    "test = test[features + ['row_id']]\n",
    "test['square_feet'] = np.log1p(test['square_feet'].values)\n",
    "\n",
    "test_v = test.drop('row_id', 1).values\n",
    "test_v = imp.transform(test_v)\n",
    "test_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palermopenano/miniconda3/envs/cpa/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNC\n",
    "\n",
    "test['meter_reading'] = np.expm1(clf.predict(test_v))\n",
    "# Save predictions as a column in a df\n",
    "# Clip to a min of 0 and infinity (a_max is None)\n",
    "test['meter_reading'] = np.clip(test['meter_reading'].values, 0, None)\n",
    "sample_submission = test[['row_id', 'meter_reading']]\n",
    "\n",
    "sample_submission.loc[:,'meter_reading'] = (\n",
    "    sample_submission.loc[:, 'meter_reading'].\n",
    "    astype('float32').\n",
    "    round(2)\n",
    ")\n",
    "\n",
    "sample_submission.loc[:,'row_id'] = (\n",
    "    sample_submission.loc[:, 'row_id'].\n",
    "    astype('int32')\n",
    ")\n",
    "\n",
    "sample_submission.memory_usage().sum() // 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNC\n",
    "sample_submission.to_csv(SUBMISSIONS_PATH / submission_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
